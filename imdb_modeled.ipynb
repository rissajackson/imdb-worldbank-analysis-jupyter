{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'swift-area-266618:imdb_modeled' already\n",
      "exists.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=US mk --dataset imdb_modeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table imdb_modeled.Movies as \n",
    "select distinct *\n",
    "from imdb_staging.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table imdb_modeled.Ratings as \n",
    "select distinct *\n",
    "from imdb_staging.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Actors AS\n",
    "SELECT * EXCEPT(primary_profession, job, ordering, actors, production_company, place_of_death, reason_of_death, imdb_name_id, date_of_death), date_of_death as reason_of_death, generate_uuid() as actor_name_id\n",
    "FROM imdb_staging.Names n INNER JOIN imdb_staging.Title_Principals t USING (imdb_name_id)\n",
    "WHERE t.category = \"actor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Directors AS\n",
    "SELECT * EXCEPT(primary_profession, job, actors, production_company, ordering, place_of_death, reason_of_death, imdb_name_id, date_of_death), generate_uuid() as director_name_id, date_of_death as reason_of_death\n",
    "FROM imdb_staging.Names n INNER JOIN imdb_staging.Title_Principals t USING (imdb_name_id)\n",
    "WHERE t.category = \"director\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Writers AS\n",
    "SELECT * EXCEPT(primary_profession, job, actors, production_company, ordering, place_of_death, reason_of_death, imdb_name_id, date_of_death), generate_uuid() as writer_name_id, date_of_death as reason_of_death\n",
    "FROM imdb_staging.Names n INNER JOIN imdb_staging.Title_Principals t USING (imdb_name_id)\n",
    "WHERE t.category = \"writer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Actor_Movie AS\n",
    "SELECT * EXCEPT(ordering, category, job)\n",
    "FROM imdb_staging.Title_Principals\n",
    "WHERE category = \"actor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Writer_Movie AS\n",
    "SELECT * EXCEPT(ordering, category, job, characters)\n",
    "FROM imdb_staging.Title_Principals\n",
    "WHERE category = \"writer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "CREATE table imdb_modeled.Director_Movie AS\n",
    "SELECT * EXCEPT(ordering, category, job, characters)\n",
    "FROM imdb_staging.Title_Principals\n",
    "WHERE category = \"director\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 44c21943-131f-43fb-8728-2033f8e160c6\n",
      "Query executing: 0.21s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 404 Not found: Table swift-area-266618:imdb_modeled.Names was not found in location US\n",
      "\n",
      "(job ID: 44c21943-131f-43fb-8728-2033f8e160c6)\n",
      "\n",
      "            -----Query Job SQL Follows-----             \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:select cast(date_of_birth as date) as date_of_birth\n",
      "   2:from imdb_modeled.Names\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(date_of_birth as date) as date_of_birth\n",
    "from imdb_modeled.Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 5804af48-7ea8-4051-9a18-c0feff006b78\n",
      "Query executing: 0.27s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 404 Not found: Table swift-area-266618:imdb_modeled.Names was not found in location US\n",
      "\n",
      "(job ID: 5804af48-7ea8-4051-9a18-c0feff006b78)\n",
      "\n",
      "            -----Query Job SQL Follows-----             \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:select cast(date_of_death as date) as date_of_death\n",
      "   2:from imdb_modeled.Names\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(date_of_death as date) as date_of_death\n",
    "from imdb_modeled.Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 54c72928-e341-4c90-9603-0a1b4563e0bb\n",
      "Query executing: 0.96s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/swift-area-266618/queries/54c72928-e341-4c90-9603-0a1b4563e0bb?location=US&timeoutMs=400&maxResults=0: Bad int64 value: $ 69225\n",
      "\n",
      "(job ID: 54c72928-e341-4c90-9603-0a1b4563e0bb)\n",
      "\n",
      "                -----Query Job SQL Follows-----                \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:select cast(usa_gross_income as INT64) as usa_gross_income\n",
      "   2:from imdb_modeled.Movies\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(usa_gross_income as INT64) as usa_gross_income\n",
    "from imdb_modeled.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 51b09a88-e80d-4701-9ca4-a94fec4f9510\n",
      "Query executing: 0.49s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/swift-area-266618/queries/51b09a88-e80d-4701-9ca4-a94fec4f9510?location=US&timeoutMs=0&maxResults=0: Bad int64 value: $ 67522\n",
      "\n",
      "(job ID: 51b09a88-e80d-4701-9ca4-a94fec4f9510)\n",
      "\n",
      "                     -----Query Job SQL Follows-----                     \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:select cast(worlwide_gross_income as INT64) as worlwide_gross_income\n",
      "   2:from imdb_modeled.Movies\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(worlwide_gross_income as INT64) as worlwide_gross_income\n",
    "from imdb_modeled.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100490</th>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100491</th>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100492</th>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100493</th>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100494</th>\n",
       "      <td>2008.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        birth_year\n",
       "0              NaN\n",
       "1              NaN\n",
       "2              NaN\n",
       "3              NaN\n",
       "4              NaN\n",
       "...            ...\n",
       "100490      2006.0\n",
       "100491      2006.0\n",
       "100492      2007.0\n",
       "100493      2007.0\n",
       "100494      2008.0\n",
       "\n",
       "[100495 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(birth_year as INT64) as birth_year\n",
    "from imdb_modeled.Actors\n",
    "order by birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>death_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100490</th>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100491</th>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100492</th>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100493</th>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100494</th>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100495 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        death_year\n",
       "0              NaN\n",
       "1              NaN\n",
       "2              NaN\n",
       "3              NaN\n",
       "4              NaN\n",
       "...            ...\n",
       "100490      2019.0\n",
       "100491      2019.0\n",
       "100492      2019.0\n",
       "100493      2019.0\n",
       "100494      2019.0\n",
       "\n",
       "[100495 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(death_year as INT64) as death_year\n",
    "from imdb_modeled.Actors\n",
    "order by death_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: 06ec3589-9f96-4fea-8f10-c0cc50ea6e87\n",
      "Query executing: 0.51s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/swift-area-266618/queries/06ec3589-9f96-4fea-8f10-c0cc50ea6e87?location=US&timeoutMs=400&maxResults=0: Invalid date: '1979'\n",
      "\n",
      "(job ID: 06ec3589-9f96-4fea-8f10-c0cc50ea6e87)\n",
      "\n",
      "             -----Query Job SQL Follows-----              \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:select cast(date_published as date) as date_published\n",
      "   2:from imdb_modeled.Movies\n",
      "    |    .    |    .    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(date_published as date) as date_published\n",
    "from imdb_modeled.Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing query with job ID: d509993b-0a99-4b22-868e-f71579f55374\n",
      "Query executing: 0.33s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR:\n",
      " 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/swift-area-266618/queries/d509993b-0a99-4b22-868e-f71579f55374?location=US&timeoutMs=400&maxResults=0: Bad int64 value: GBP 80000\n",
      "\n",
      "(job ID: d509993b-0a99-4b22-868e-f71579f55374)\n",
      "\n",
      "      -----Query Job SQL Follows-----      \n",
      "\n",
      "    |    .    |    .    |    .    |\n",
      "   1:select cast(budget as INT64) as budget\n",
      "   2:from imdb_modeled.Movies\n",
      "    |    .    |    .    |    .    |\n"
     ]
    }
   ],
   "source": [
    "%%bigquery\n",
    "select cast(budget as INT64) as budget\n",
    "from imdb_modeled.Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries for checking duplicates in primary key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writers Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  55867"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  55867"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT writer_name_id) FROM imdb_modeled.Writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  100495"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  100495"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT actor_name_id) FROM imdb_modeled.Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  43210"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*)\n",
    "FROM imdb_modeled.Movies r LEFT JOIN imdb_modeled.Actors m ON r.imdb_title_id = m.imdb_title_id\n",
    "WHERE m.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f0_\n",
       "0  100495"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actor_Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  45174"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_name_id) FROM imdb_modeled.Actor_Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directors Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  40106"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  40106"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT director_name_id) FROM imdb_modeled.Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  81273"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  81273"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_title_id) FROM imdb_modeled.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Actors'> referenced by query SELECT name, birth_name, height, bio, birth_details, birth_year, place_of_birth, death_details, death_year, spouses, divorces, children, known_for_titles, imdb_title_id, actor_name_id, category, characters, reason_of_death FROM imdb_modeled.Actors WHERE birth_year IS NOT NULL AND death_year IS NOT NULL limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset swift-area-266618:temp_dataset_838cfed7e01d44a585c13ccc5c694900 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table swift-area-266618.imdb_modeled.Actors_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'characters'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actor_name_id'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583519683584\n",
      " etag: 'qYYLbEwQ9e6XjgH6Nh2alA=='\n",
      " id: 'swift-area-266618:imdb_modeled.Actors_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583519683654\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'characters'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actor_name_id'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/swift-area-266618/datasets/imdb_modeled/tables/Actors_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Actors_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Actors_beam.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors_Beam table - Primary Key Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actors_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT actor_name_id) FROM imdb_modeled.Actors_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors_Beam table - Not child table so no Foreign Key Verification. Table has no foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmplh4k78qw', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://nullbusters_data/staging/actors.1583719930.732705/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmplh4k78qw', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://nullbusters_data/staging/actors.1583719930.732705/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/actors.1583719930.732705/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T02:12:16.865317Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_19_12_15-1558838999990656175'\n",
      " location: 'us-central1'\n",
      " name: 'actors'\n",
      " projectId: 'swift-area-266618'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T02:12:16.865317Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_19_12_15-1558838999990656175]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_19_12_15-1558838999990656175?project=swift-area-266618\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_12_15-1558838999990656175 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:15.848Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_19_12_15-1558838999990656175.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:15.848Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_19_12_15-1558838999990656175. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:20.114Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:20.674Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.129Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.158Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Output/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.192Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.231Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.262Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.369Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.601Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.634Z: JOB_MESSAGE_DETAILED: Fusing consumer Format Years into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.668Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.700Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WriteBundles/WriteBundles into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.734Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.767Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Pair into Write log Input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.795Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.830Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Reify into Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.858Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Write into Write log Input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.880Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.908Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Extract into Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.931Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Pair into Write log Output/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.953Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Output/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:21.975Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Reify into Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.001Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Write into Write log Output/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.039Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Output/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.072Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Extract into Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.096Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/InitializeWrite into Write log Input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.134Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/InitializeWrite into Write log Output/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.167Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.190Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_12_15-1558838999990656175 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.221Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.253Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.403Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.467Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.502Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.532Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.554Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.585Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.622Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.630Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.679Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.703Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:22.816Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:12:45.104Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:14:36.220Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:14:36.251Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.622Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.686Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.753Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.831Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.885Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.925Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.964Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:10.971Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:11.021Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:11.031Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:11.067Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:11.089Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.310Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.397Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.433Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.501Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.541Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.560Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.572Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.587Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.624Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.665Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.701Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.735Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:14.818Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:15:15.746Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_9707272152998342911\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_9707272152998342911\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:16:22.827Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_9707272152998342911\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:16:23.247Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_11709124155468128504\" started. You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_11709124155468128504\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:16:53.572Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_11709124155468128504\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:16:53.610Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_11709124155468128504\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:07.321Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_9707272152998344315\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_9707272152998344315\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:17.763Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_9707272152998344315\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.218Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.287Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.322Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.339Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.374Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.412Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:18.450Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.002Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.068Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.138Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.173Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.193Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.229Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.255Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.301Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:34.372Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.432Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.503Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.663Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.696Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.710Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.752Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.778Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.822Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:37.887Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.202Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.265Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.334Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.389Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.451Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:41.527Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:45.084Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.270Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.331Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.402Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.456Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.524Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:49.585Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:53.280Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:53.354Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:53.474Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:53.536Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:17:53.562Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:19:43.258Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:19:43.305Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:19:43.342Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_12_15-1558838999990656175 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Actors_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Directors'> referenced by query SELECT name, birth_name, height, bio, birth_details, birth_year, place_of_birth, death_details, death_year, spouses, divorces, children, known_for_titles, imdb_title_id, director_name_id, category, reason_of_death FROM imdb_modeled.Directors WHERE birth_year IS NOT NULL AND death_year IS NOT NULL limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset swift-area-266618:temp_dataset_db741c19b21544c2ad3ade883b026657 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table swift-area-266618.imdb_modeled.Directors_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director_name_id'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583691387740\n",
      " etag: 'l773IF0k+pEK0jei2jdumA=='\n",
      " id: 'swift-area-266618:imdb_modeled.Directors_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583691387779\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director_name_id'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/swift-area-266618/datasets/imdb_modeled/tables/Directors_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Directors_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Directors_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp2p9a7s7p', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://nullbusters_data/staging/directors.1583719449.096660/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp2p9a7s7p', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://nullbusters_data/staging/directors.1583719449.096660/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/directors.1583719449.096660/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T02:04:14.910212Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_19_04_13-1322047491472172253'\n",
      " location: 'us-central1'\n",
      " name: 'directors'\n",
      " projectId: 'swift-area-266618'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T02:04:14.910212Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_19_04_13-1322047491472172253]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_19_04_13-1322047491472172253?project=swift-area-266618\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_04_13-1322047491472172253 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:13.770Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_19_04_13-1322047491472172253.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:13.770Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_19_04_13-1322047491472172253. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:20.571Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:21.253Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:21.920Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:21.954Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Output/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:21.989Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.026Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.062Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.218Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.624Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.703Z: JOB_MESSAGE_DETAILED: Fusing consumer Format Years into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.760Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.797Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WriteBundles/WriteBundles into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.835Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.880Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Pair into Write log Input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.918Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:22.968Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Reify into Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.020Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Write into Write log Input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.082Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.146Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Extract into Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.223Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Pair into Write log Output/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.281Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Output/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.334Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Reify into Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.417Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Write into Write log Output/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.460Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Output/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.520Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Extract into Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.570Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/InitializeWrite into Write log Input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.611Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/InitializeWrite into Write log Output/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.693Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.729Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.765Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:23.812Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.044Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.132Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.186Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.186Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.231Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.232Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.280Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.386Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.426Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.565Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:24.608Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_04_13-1322047491472172253 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:04:48.199Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:19.208Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:19.241Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.096Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.185Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.207Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.305Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.336Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.359Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.374Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.400Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.433Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.438Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.460Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:06:58.499Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.670Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.742Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.776Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.850Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.885Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.899Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.912Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.949Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.969Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:01.973Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:02.008Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:02.041Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:02.079Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:07:03.383Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_10758494579308085515\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_10758494579308085515\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:08:13.779Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_10758494579308085515\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:08:14.345Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_2461339449827695653\" started. You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_2461339449827695653\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:08:44.727Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_2461339449827695653\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:08:44.778Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_2461339449827695653\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:08:55.127Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_10758494579308088287\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_10758494579308088287\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:05.588Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_10758494579308088287\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.152Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.211Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.237Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.255Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.292Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.325Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:06.364Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.731Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.826Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.879Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.916Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.931Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:19.970Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:20Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:20.036Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:20.098Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.583Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.638Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.694Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.720Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.742Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.758Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.793Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.820Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:26.877Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.654Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.709Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.770Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.826Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.894Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:30.961Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:33.947Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.250Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.321Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.385Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.438Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.512Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:38.591Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:42.048Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:42.108Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:42.234Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:42.295Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:09:42.336Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:11:36.023Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:11:36.070Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:11:36.095Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_19_04_13-1322047491472172253 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Directors_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Writers'> referenced by query SELECT name, birth_name, height, bio, birth_details, birth_year, place_of_birth, death_details, death_year, spouses, divorces, children, known_for_titles, imdb_title_id, writer_name_id, category, reason_of_death FROM imdb_modeled.Writers WHERE birth_year IS NOT NULL AND death_year IS NOT NULL limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset swift-area-266618:temp_dataset_691f72e16cb843949ebf85aa0cc106fb does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table swift-area-266618.imdb_modeled.Writers_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer_name_id'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1583632175115\n",
      " etag: 'IrCeQJHQZORqCLLoIRiw5A=='\n",
      " id: 'swift-area-266618:imdb_modeled.Writers_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583632175147\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_name'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'height'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'bio'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'birth_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'place_of_birth'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_details'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'death_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'spouses'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'divorces'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'children'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'known_for_titles'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'category'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reason_of_death'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer_name_id'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/swift-area-266618/datasets/imdb_modeled/tables/Writers_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Writers_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Writers_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp4ga2g0aw', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://nullbusters_data/staging/student-df2.1583718943.308974/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmp4ga2g0aw', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://nullbusters_data/staging/student-df2.1583718943.308974/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df2.1583718943.308974/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T01:55:49.369819Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_18_55_48-13533780675642173231'\n",
      " location: 'us-central1'\n",
      " name: 'student-df2'\n",
      " projectId: 'swift-area-266618'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T01:55:49.369819Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_18_55_48-13533780675642173231]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_18_55_48-13533780675642173231?project=swift-area-266618\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_18_55_48-13533780675642173231 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:48.251Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_18_55_48-13533780675642173231. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:48.251Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_18_55_48-13533780675642173231.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:51.627Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:52.484Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.013Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.073Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Output/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.101Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.138Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.169Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.263Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.512Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.549Z: JOB_MESSAGE_DETAILED: Fusing consumer Format Years into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.598Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.628Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WriteBundles/WriteBundles into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.651Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.689Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Pair into Write log Input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.723Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.758Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Reify into Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.797Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Write into Write log Input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.831Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.869Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Extract into Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.894Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Pair into Write log Output/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.919Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Output/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.947Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Reify into Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:53.980Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Write into Write log Output/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.002Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Output/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.030Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Extract into Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.051Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/InitializeWrite into Write log Input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.074Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/InitializeWrite into Write log Output/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.108Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.134Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.157Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.192Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.334Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.389Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.422Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.435Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.455Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.472Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.484Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.530Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.530Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_18_55_48-13533780675642173231 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.606Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:55:54.641Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:56:19.229Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:01.371Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:01.400Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.015Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.087Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.111Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.184Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.209Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.242Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.245Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.273Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.292Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.300Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.337Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:37.363Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.286Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.381Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.408Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.476Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.507Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.525Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.529Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.582Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:40.656Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:41.026Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:41.026Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:41.072Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:41.109Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:58:41.896Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_17781245389538499316\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_17781245389538499316\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:59:59.346Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_17781245389538499316\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T01:59:59.963Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_3531438793094660823\" started. You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_3531438793094660823\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:30.324Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_3531438793094660823\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:30.348Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_3531438793094660823\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:41.368Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_17781245389538497272\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_17781245389538497272\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:51.872Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_17781245389538497272\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.389Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.453Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.485Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.504Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.537Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.567Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:00:52.602Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.493Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.553Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.609Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.645Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.670Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.703Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.729Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.772Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:06.832Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:09.830Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:09.897Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:09.958Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:09.989Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:10.012Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:10.037Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:10.071Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:10.102Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:10.157Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:13.897Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:13.966Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:14.037Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:14.096Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:14.165Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:14.239Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:15.728Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:15.802Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:15.871Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:15.927Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:15.994Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:16.063Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:20.552Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:24.564Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:24.652Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:24.765Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:24.839Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:01:24.868Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:03:08.575Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:03:08.615Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T02:03:08.641Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_18_55_48-13533780675642173231 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Writers_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Movies'> referenced by query SELECT imdb_title_id, title, original_title, year, genre, duration, country, language, director, writer, production_company, actors, description, avg_vote, votes, budget, usa_gross_income, worlwide_gross_income, metascore, reviews_from_users, reviews_from_critics FROM imdb_modeled.Movies WHERE usa_gross_income IS NOT NULL and worlwide_gross_income IS NOT NULL limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset swift-area-266618:temp_dataset_ff81bbf9d84c4f2ba551f4fd9505aec9 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table swift-area-266618.imdb_modeled.Movies_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'String'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'original_title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'genre'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'duration'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'production_company'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actors'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'description'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'avg_votes'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'votes'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'usa_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'metascore'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_users'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_critics'\n",
      " type: 'FLOAT'>]>. Result: <Table\n",
      " creationTime: 1583693618516\n",
      " etag: 'MdzL1Sre620fuNJrL7I3yw=='\n",
      " id: 'swift-area-266618:imdb_modeled.Movies_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583693618551\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'original_title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'genre'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'duration'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'production_company'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actors'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'description'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'avg_votes'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'votes'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'usa_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'metascore'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_users'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_critics'\n",
      " type: 'FLOAT'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/swift-area-266618/datasets/imdb_modeled/tables/Movies_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Movies_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Movies_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpe87om4ug', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://nullbusters_data/staging/student-df5.1587957784.963273/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpe87om4ug', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://nullbusters_data/staging/student-df5.1587957784.963273/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/student-df5.1587957784.963273/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-04-27T03:23:10.631277Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-04-26_20_23_09-7124559963802349152'\n",
      " location: 'us-central1'\n",
      " name: 'student-df5'\n",
      " projectId: 'swift-area-266618'\n",
      " stageStates: []\n",
      " startTime: '2020-04-27T03:23:10.631277Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-04-26_20_23_09-7124559963802349152]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-04-26_20_23_09-7124559963802349152?project=swift-area-266618\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_23_09-7124559963802349152 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:09.696Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-04-26_20_23_09-7124559963802349152.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:09.696Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-04-26_20_23_09-7124559963802349152. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:12.673Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.208Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.647Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.686Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Output/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.715Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.761Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.798Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:13.890Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.124Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.152Z: JOB_MESSAGE_DETAILED: Fusing consumer Format Years into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.193Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.222Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WriteBundles/WriteBundles into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.258Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.296Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Pair into Write log Input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.325Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.368Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Reify into Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.409Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Write into Write log Input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.446Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.478Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Extract into Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.511Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Pair into Write log Output/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.550Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Output/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.589Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Reify into Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.628Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Write into Write log Output/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.666Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Output/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.701Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Extract into Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.741Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/InitializeWrite into Write log Input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.765Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/InitializeWrite into Write log Output/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.797Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.828Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.864Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:14.905Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.184Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.260Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.298Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.310Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.331Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.341Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.363Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.407Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.407Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.472Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:15.508Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_23_09-7124559963802349152 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:23:40.415Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:21.768Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:21.810Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.511Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.581Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.604Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.679Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.712Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.745Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.746Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.752Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.800Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.819Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.856Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:55.891Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:58.857Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:58.934Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:58.960Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.027Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.060Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.077Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.090Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.107Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.140Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.145Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.177Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.213Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.252Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:25:59.913Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_3046545848349185972\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_3046545848349185972\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:27:10.792Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_3046545848349185972\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:27:11.467Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_4320054409870975934\" started. You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_4320054409870975934\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:27:41.846Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_4320054409870975934\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:27:41.878Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_4320054409870975934\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:09.386Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_3046545848349185384\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_3046545848349185384\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:29.969Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_3046545848349185384\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.447Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.524Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.559Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.578Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.609Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.644Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:30.677Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.619Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.707Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.790Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.851Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.900Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.938Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:43.955Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:44.023Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:44.101Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:46.863Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:46.931Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.008Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.042Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.058Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.088Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.124Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.163Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:47.239Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.559Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.621Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.695Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.749Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.813Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:50.884Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:54.618Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.589Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.653Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.725Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.763Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.863Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:28:57.959Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:29:01.204Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:29:01.285Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:29:01.409Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:29:01.484Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:29:01.504Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:31:00.775Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:31:00.826Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:31:00.865Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_23_09-7124559963802349152 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Movies_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'Movies_Beam_DF'> referenced by query SELECT imdb_title_id, title, original_title, year, genre, duration, country, language, director, writer, production_company, actors, description, avg_votes, votes, budget_currency, budget, usa_gross_income, worlwide_gross_income_currency, worlwide_gross_income, metascore, reviews_from_users, reviews_from_critics FROM imdb_modeled.Movies_Beam_DF WHERE country IS NOT NULL limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset swift-area-266618:temp_dataset_c7acc7fa83bb4c2ba687d1c1f0af4e44 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table swift-area-266618.imdb_modeled.New_Movies_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'String'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'original_title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'genre'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'duration'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'other_countries'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'production_company'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actors'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'description'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'avg_votes'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'votes'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'usa_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'metascore'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_users'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_critics'\n",
      " type: 'FLOAT'>]>. Result: <Table\n",
      " creationTime: 1587958896398\n",
      " etag: '3FqTRrjQKsgoF1TsmKSHdQ=='\n",
      " id: 'swift-area-266618:imdb_modeled.New_Movies_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1587958896430\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'imdb_title_id'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'original_title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'genre'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'duration'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'country'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'other_countries'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'language'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'director'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'writer'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'production_company'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'actors'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'description'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'avg_votes'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'votes'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'budget'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'usa_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income_currency'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'worlwide_gross_income'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'metascore'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_users'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'reviews_from_critics'\n",
      " type: 'FLOAT'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/swift-area-266618/datasets/imdb_modeled/tables/New_Movies_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'imdb_modeled'\n",
      " projectId: 'swift-area-266618'\n",
      " tableId: 'New_Movies_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run New_Movies_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpaepfj887', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://nullbusters_data/staging/new-movies.1587959671.412089/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpaepfj887', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://nullbusters_data/staging/new-movies.1587959671.412089/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://nullbusters_data/staging/new-movies.1587959671.412089/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-04-27T03:54:36.812935Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-04-26_20_54_35-8466217145901429716'\n",
      " location: 'us-central1'\n",
      " name: 'new-movies'\n",
      " projectId: 'swift-area-266618'\n",
      " stageStates: []\n",
      " startTime: '2020-04-27T03:54:36.812935Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-04-26_20_54_35-8466217145901429716]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-04-26_20_54_35-8466217145901429716?project=swift-area-266618\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_54_35-8466217145901429716 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:35.783Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-04-26_20_54_35-8466217145901429716. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:35.783Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-04-26_20_54_35-8466217145901429716.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:38.878Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:39.395Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:39.932Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:39.957Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Output/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:39.985Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log Input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.020Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.050Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.123Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.348Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.375Z: JOB_MESSAGE_DETAILED: Fusing consumer Format Years into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.405Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.428Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WriteBundles/WriteBundles into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.453Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format Years\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.481Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Pair into Write log Input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.507Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.529Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Reify into Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.555Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/Write into Write log Input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.575Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.602Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/Extract into Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.626Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Pair into Write log Output/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.654Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log Output/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.673Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Reify into Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.701Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/Write into Write log Output/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.730Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow into Write log Output/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.756Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/Extract into Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.779Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Input/Write/WriteImpl/InitializeWrite into Write log Input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.804Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log Output/Write/WriteImpl/InitializeWrite into Write log Output/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.832Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.857Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.890Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:40.918Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.110Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.175Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.202Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.214Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.229Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.238Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.256Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.293Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.311Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.343Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:54:41.369Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_54_35-8466217145901429716 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:55:04.958Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:56:42.235Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:56:42.261Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.748Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/DoOnce/Read+Write log Input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.838Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.871Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.933Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.967Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:15.988Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.004Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.028Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.073Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.081Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.114Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:16.156Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.126Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/DoOnce/Read+Write log Output/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.186Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.222Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.293Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.318Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.342Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.356Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.362Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.402Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.406Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.434Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.467Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:19.506Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:57:20.291Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_12603297622810325992\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_12603297622810325992\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:58:30.779Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_12603297622810325992\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:58:31.392Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_9666269287058074674\" started. You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_9666269287058074674\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:01.897Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_9666269287058074674\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:01.935Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_9666269287058074674\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:30.273Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_12603297622810325068\". You can check its status with the bq tool: \"bq show -j --project_id=swift-area-266618 dataflow_job_12603297622810325068\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:40.778Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_12603297622810325068\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.196Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format Years+Write log Input/Write/WriteImpl/WriteBundles/WriteBundles+Write log Output/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log Input/Write/WriteImpl/Pair+Write log Input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Input/Write/WriteImpl/GroupByKey/Reify+Write log Input/Write/WriteImpl/GroupByKey/Write+Write log Output/Write/WriteImpl/Pair+Write log Output/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log Output/Write/WriteImpl/GroupByKey/Reify+Write log Output/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.255Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.272Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.296Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.312Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.343Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:41.368Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.419Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/GroupByKey/Read+Write log Output/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Output/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.469Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.521Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.547Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.564Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.596Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.612Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.656Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:55.698Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.686Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/GroupByKey/Read+Write log Input/Write/WriteImpl/GroupByKey/GroupByWindow+Write log Input/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.744Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.802Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.830Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.842Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.866Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.895Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.920Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T03:59:58.977Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.370Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.424Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.483Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.518Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.564Z: JOB_MESSAGE_DEBUG: Value \"Write log Output/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:01.621Z: JOB_MESSAGE_BASIC: Executing operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.015Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.072Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.123Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.171Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.228Z: JOB_MESSAGE_DEBUG: Value \"Write log Input/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:05.298Z: JOB_MESSAGE_BASIC: Executing operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:08.871Z: JOB_MESSAGE_BASIC: Finished operation Write log Input/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:12.163Z: JOB_MESSAGE_BASIC: Finished operation Write log Output/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:12.240Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:12.356Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:12.412Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:00:12.448Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:01:49.263Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:01:49.312Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-27T04:01:49.356Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-26_20_54_35-8466217145901429716 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run New_Movies_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Primary and Foreign keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actors_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT actor_name_id) FROM imdb_modeled.Actors_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  26604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  26604"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT actor_name_id) FROM imdb_modeled.Actors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Actors_Beam_DF a LEFT JOIN imdb_modeled.Actor_Movie m ON a.imdb_title_id = m.imdb_title_id WHERE m.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directors_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Directors_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT director_name_id) FROM imdb_modeled.Directors_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  11182"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Directors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  11182"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT director_name_id) FROM imdb_modeled.Directors_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Directors_Beam_DF d LEFT JOIN imdb_modeled.Director_Movie m ON d.imdb_title_id = m.imdb_title_id WHERE m.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Writers_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Writers_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT writer_name_id) FROM imdb_modeled.Writers_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writers_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  20647"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Writers_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  20647"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT writer_name_id) FROM imdb_modeled.Writers_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Writers_Beam_DF w LEFT JOIN imdb_modeled.Writer_Movie m ON w.imdb_title_id = m.imdb_title_id WHERE m.imdb_title_id IS NULL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writers_Beam and Writers_Beam_DF tables - Not child tables so no Foreign Key Verifications. Tables have no foreign keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Movies_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_title_id) FROM imdb_modeled.Movies_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14154"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Movies_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14154"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_title_id) FROM imdb_modeled.Movies_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foreign key check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Movies_Beam_DF m RIGHT JOIN imdb_modeled.Actor_Movie a ON m.imdb_title_id = a.imdb_title_id WHERE a.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Movies_Beam_DF m RIGHT JOIN imdb_modeled.Director_Movie d ON m.imdb_title_id = d.imdb_title_id WHERE d.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.Movies_Beam_DF m RIGHT JOIN imdb_modeled.Writer_Movie w ON m.imdb_title_id = w.imdb_title_id WHERE w.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New_Movies_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.New_Movies_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_title_id) FROM imdb_modeled.New_Movies_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.New_Movies_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  14151"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(DISTINCT imdb_title_id) FROM imdb_modeled.New_Movies_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foreign key check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.New_Movies_Beam_DF m RIGHT JOIN imdb_modeled.Actor_Movie a ON m.imdb_title_id = a.imdb_title_id WHERE a.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.New_Movies_Beam_DF m RIGHT JOIN imdb_modeled.Director_Movie d ON m.imdb_title_id = d.imdb_title_id WHERE d.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0    0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "SELECT COUNT(*) FROM imdb_modeled.New_Movies_Beam_DF m RIGHT JOIN imdb_modeled.Writer_Movie w ON m.imdb_title_id = w.imdb_title_id WHERE w.imdb_title_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
